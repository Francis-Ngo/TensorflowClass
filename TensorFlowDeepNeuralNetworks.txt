Hello, and welcome! In this video, we will provide an overview of several deep neural network models, and their applications. To better understand Deep Learning, let’s first take a look at different deep neural networks and their applications, namely: • Convolutional Neural Networks (or CNNs) • Recurrent Neural Networks (or RNNs) • Restricted Boltzmann Machines (or RBMs) • Deep Belief Networks (or DBNs), and finally • Autoencoders. Let’s start with the Convolutional Neural Network, and see how it helps us to do a task, such as image classification. Assume that you have a dataset made up of a great many photos of cats and dogs, and you want to build a model that can recognize and differentiate them. This model is supposed to look at this particular sample set of images and learn from them, toward becoming trained. Later, given an unseen image of either a cat or a dog, we should be able to use this trained model to recognize the image as being one or the other. Traditionally, your first step in building such a model would be “feature extraction.” That is, to choose the best features from your images, and then use those features in a classification algorithm, such as a shallow Neural Network. Ideally, the result would be a model that, upon analyzing a new image, could accurately distinguish the animal in that photo as being either a “cat” or a “dog.” There are countless features that could be extracted from the image, such as color, object edges, pixel location, and so on. Of course, the better that you can define the feature sets, the more accurate and efficient your image-classification will be. In fact, in the last two decades, there has been a lot of scientific research in the field of image processing, that is devoted to helping data scientists find the best feature sets from images, for the purposes of classification. However, as you can imagine, the process of selecting and using the best features is tremendously time-consuming and is often ineffective. Furthermore, extending the features to other types of images becomes an even greater challenge. Indeed, it’s easy to see how difficult it would be to apply the features we’ve used to discriminate cats and dogs, to other discrimination tasks, such as recognizing hand-written digits, for example. Therefore, the importance of feature selection can’t be overstated. Enter “convolutional neural networks”. Suddenly, without having to find or select features, this network automatically and effectively finds the best features for you. So instead of you choosing what image features to use in classifying dogs vs. cats, Convolutional Neural Networks can automatically find those features and classify the images for you. So, we can say that a Convolutional Neural Network - or CNN for short - is a deep learning approach that learns directly from samples in a way that is much more effective than traditional Neural networks. CNNs achieve this type of automatic feature selection and classification through multiple specific layers of sophisticated mathematical operations. Through multiple layers, a CNN learns multiple levels of feature sets at different levels of abstraction. And this leads to very effective classification. CNNs have gained a lot of attention in the machine learning community over the last few years. This is due to the wide range of applications where CNNs excel, especially machine vision projects, including image recognition or classification, such as distinguishing animal photos or digit recognition, to skin cancer classification. CNNs are also used in object detection, for example real-time recognition of passengers in images captured by self-driving cars. Or coloring black and white images, and creating art images. Now, let’s look at Recurrent Neural networks and the types of situations in which they can be used, to solve a problem. A Recurrent Neural Network, or RNN for short, is a type of deep learning approach, that tries to solve the problem of modeling sequential data. Whenever the points in a dataset are dependent on the previous points, the data is said to be sequential. For example, a stock market price is a sequential type of data because the price of any given stock in tomorrow’s market, to a great extent, depends on its price today. As such, predicting the stock price tomorrow, is something that RNNs can be used for. We simply need to feed the network with the sequential data, it then maintains the context of the data and thus, learns the patterns within the data. We can also use RNNs for sentiment analysis. Let’s say for example, you’re scrolling through your product catalogue on a social network site and you see many comments related to a particular product of yours. Rather than reading through dozens and dozens of comments yourself and having to manually calculate if they were mostly positive, you can let an RNN do that for you. Indeed, an RNN can examine the sentiment of keywords in those reviews. Please remember, though, that the sequence of the words or sentences, as well as the context in which they are used, is very important as well. By feeding a sentence into an RNN, it takes all of this into account and determines if it the sentiment within it those product reviews are positive or negative. RNNs can also be used to predict the next word in a sentence. I’m sure we’ve all seen how our mobile phone suggests words when we’re typing an email or a text. This is a type of language modeling within RNN, where the model has learned from a big textual corpus, and now can predict the next word in the sentence. As you can see, thinking in a sequential way, the word being suggested is very dependent on the previously typed words and the context of that message. When needing quick translation of certain words into another language, a great many people today, use the translation service of Google translator. We enter a sequence of words in English and it outputs a sequence of the words in French, as seen here. This type of text translation is another example of how RNNs can be used. This task is not based on a word-by-word translation and applying grammar rules. Instead, it is a probability model that has been trained on lots of data where the exact same text is translated into another language. Speech-to-text is yet another useful and increasingly common application of RNNs. In this case, the recognized voice is not only based on the word sound; RNNs also use the context around that sound to accurately recognize of the words being spoken into the device’s microphone. Now, let’s look at another type of neural network called a Restricted Boltzman Machine. Restricted Boltzman Machines, or RBMs, are used to find the patterns in data in an unsupervised manner. They are shallow neural nets that learn to reconstruct data by themselves. They are very important models, because they can automatically extract meaningful features from a given input, without the need to label them. RBMs might not be outstanding if you look at them as independent networks, but they are significant as building blocks of other networks, such as Deep Belief Networks. Essentially, RBMs are useful for unsupervised tasks such as: • feature extraction, • dimensionality reduction, • pattern recognition, • recommender systems, • handling missing values, and • topic modeling. Now let’s look at Deep Belief Networks and see how they are built on top of RBMs. A Deep Belief Network is a network that was invented to solve an old problem in traditional artificial neural networks. Which problem? The back-propagation problem, that can often cause “local minima” or “vanishing gradients” issues in the learning process. A DBN is built to solve this by the stacking of multiple RBMs. So, what are the applications of DBNs? DBNs are generally used for classification -- same as traditional MLPs. So, one of the most important applications of DBNs is image recognition. The important part to remember, here, is that a DBN is a very accurate discriminative classifier. As such, we don’t need a big set of labeled data to train a Deep Belief Network; in fact, a small set works fine because feature extraction is unsupervised by a stack of RBMs. Now, let’s look at Autoencoders. Much like RBMs, Autoencoders were invented to address the issue of extracting desirable features. And again, much like RBMs, Autoencoders try to recreate a given input, but do so with a slightly different network architecture and learning method. Autoencoders take a set of unlabeled inputs, encodes them into short codes, and then uses those to reconstruct the original image, while extracting the most valuable information from the data. What are the applications of Autoencoders? Well, Autoencoders are employed in some of the largest deep learning applications, especially for unsupervised tasks. As the encoder part of the network, Autoencoders compress data from the input layer into a short code -- a method that can be used for “dimensionality reduction” tasks. Also, in stacking multiple Autoencoder layers, the network learns multiple levels of representation at different levels of abstraction. For example, to detect a face in an image, the network encodes the primitive features, like the edges of a face. Then, the first layer's output goes to the second Autoencoder, to encode the less local features, like the nose, and so on. Therefore, it can be used for Feature Extraction and image recognition. By now, you should have a good sense of deep neural networks. This concludes this video … Thanks for watching.